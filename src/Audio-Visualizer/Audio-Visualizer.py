import pyaudiowpatch as pyaudio
import numpy as np
import sounddevice as sd
import numpy as np
from textual import work
from textual.app import App, ComposeResult
from textual_plotext import PlotextPlot
from textual.message import Message
from textual.reactive import reactive
from textual import on

# a QThread for audio data reading
class AudioData():

    def __init__(self):
        self.p=pyaudio.PyAudio() #start PyAudio instance
        self.stream:pyaudio.Stream

        # TODO: make rate and channels variable based on the audio device configuration
        self.CHUNK = 2**11       #num of data points read at one time
        self.RATE = 48000        #time resolution of the recording device (Hz)
        self.CHANNELS = 2        #stereo usually has 2 channels
        self.maxValue = 2**15
        self.bars = 50

        default_output = sd.query_devices(kind='output')    #find default audio device
        print(f"Default: {default_output['name']}")

        #for all devices connected, compare names. If default device name has the word "Loopback", set as PyAudio device index
        for i in range(self.p.get_device_count()):
            dev = self.p.get_device_info_by_index(i)
            print ( i, dev.get('name'))
            if default_output['name'] in dev.get('name') and "[Loopback]" in dev.get('name'):
                print (f"This is default device from array {dev.get('name')} at index {i}")
                dev_index = i   #assign dev index to current index

        self.stream = self.p.open(format=pyaudio.paInt16,channels=self.CHANNELS, rate=self.RATE, input=True, input_device_index=dev_index, frames_per_buffer=self.CHUNK)

    # get the left and right data
    def get_lr_data(self):
        data = np.frombuffer(self.stream.read(1024),dtype=np.int16)
        dataL = data[0::2]
        dataR = data[1::2]
        return dataL, dataR

    # close audio stream and terminate pyaudio
    def close(self):
        self.stream.stop_stream()
        self.stream.close()
        self.p.terminate()

class TuiApp(App):

    peak_plot = reactive(PlotextPlot(), always_update=True, bindings=True)
    spec_plot = reactive(PlotextPlot(), always_update=True, bindings=True)

    class GraphUpdateMessage(Message):
        def __init__(self) -> None:
            super().__init__()

    def __init__(self):
        super().__init__()
        self.audio_data = AudioData()

        # how long the graph is
        self.num_samples = 50

        # create list for each audio channel peak
        self.left_peak_audio_levels = [0] * self.num_samples
        self.right_peak_audio_levels = [0] * self.num_samples
        
        # how many samples generated by rfttn
        self.num_spec_bytes = 513

        self.left_spec_audio_levels = np.array([0] * self.num_spec_bytes)
        self.right_spec_audio_levels = np.array([0] * self.num_spec_bytes)

        # create horizontal list i.e x-axis
        self.dataL_x = [i for i in range(self.num_spec_bytes)]
        self.dataR_x = [i for i in range(self.num_spec_bytes)]

    def compose(self) -> ComposeResult: # setup the UI
        print('composing')
        yield self.peak_plot # display the peak plot above
        yield self.spec_plot # the spec plot

    def on_mount(self) -> None:
        print('mounting')
        self.peak_plot.plt.title("Peak Plot")
        self.spec_plot.plt.title("Spec Plot")
        self.format_audio_data()._start(self) # start the worker
        self.capture_mouse(None)

    # this function is the worker and it does the WORK
    # basically reading and formatting the data to be graphed
    @work(exclusive=False, thread=True)
    async def format_audio_data(self):
        while (self.is_running):
            lrdata = self.audio_data.get_lr_data()
            dataL, dataR = lrdata
            peakL = np.abs(np.max(dataL)-np.min(dataL))/self.audio_data.maxValue
            peakR = -1 * np.abs(np.max(dataR)-np.min(dataR))/self.audio_data.maxValue

            self.left_peak_audio_levels.pop(0)
            self.right_peak_audio_levels.pop(0)

            self.left_peak_audio_levels.append(peakL)
            self.right_peak_audio_levels.append(peakR)

            # alpha filter smoothing formula: smoothed = (new_data * alpha) + (last_smoothed * beta)
            #                                   where last_smoothed = the smoothed value from the previous new_data collection
            #                                   alpha is a float percent (0.0 through 1.0)
            #                                   beta = 1 - alpha
            # parameters for alpha filter
            alpha = 0.5 # or a 50% weight with the last sample
            beta = 1 - alpha

            # spectrogram is tough and requires FAST FORIER TRANSFORMS which is diffeq stuff so we'll let numpy handle the specifics
            # learned what i needed from this https://www.yhoka.com/en/posts/fft-python/

            dataL_y = np.abs(np.fft.rfftn(dataL).astype(np.float64))
            self.dataL_x = np.fft.rfftfreq(len(dataL), 1 / self.audio_data.RATE)
            self.left_spec_audio_levels = (dataL_y * alpha) + (self.left_spec_audio_levels * beta) # applying alpha filter

            dataR_y = -1 * np.abs(np.fft.rfftn(dataR).astype(np.float64))
            self.dataR_x = np.fft.rfftfreq(len(dataR), 1 / self.audio_data.RATE)
            self.right_spec_audio_levels = (dataR_y * alpha) + (self.right_spec_audio_levels * beta) # applying alpha filter

            self.post_message(self.GraphUpdateMessage()) # textual widgets cant be updated within a threaded worker so we send a message to say new data is ready
    
    @on(GraphUpdateMessage)
    async def update_plots(self):
        self.peak_plot.plt.clear_data()
        self.peak_plot.plt.ylim(-0.50, 0.50)

        self.peak_plot.plt.bar(self.left_peak_audio_levels, width=.5)
        self.peak_plot.plt.bar(self.right_peak_audio_levels, width=.5)

        self.spec_plot.plt.clear_data()
        self.spec_plot.plt.ylim(-900000, 900000)
        self.spec_plot.plt.xlim(0, 5000)

        self.spec_plot.plt.bar(self.dataL_x, self.left_spec_audio_levels, width = 0.0001)
        self.spec_plot.plt.bar(self.dataR_x, self.right_spec_audio_levels, width = 0.0001)

        result = self.render()

    def render(self):
        result = super().render()
        self.peak_plot = self.peak_plot.refresh(self.peak_plot.region)
        self.peak_plot.focus()
        self.spec_plot = self.spec_plot.refresh(self.spec_plot.region)
        self.spec_plot.focus()

        return result


# main method
if __name__ == "__main__":
    tui_app = TuiApp() # make the app object
    tui_app.run() # run the app object